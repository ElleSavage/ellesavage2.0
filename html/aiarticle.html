<!DOCTYPE html>

<html lang='en'>

<head>

  <meta charset='UTF-8'> 
  <title>Elle Savage's Blog</title>

  <link rel='stylesheet' href='articlestyle.css'>
 <link rel='stylesheet' href='https://fonts.googleapis.com/css?family=Rochester'> 

</head>

<body>

<img src='savlogo.png' alt='Savage cursive logo' id='logo'>

	<div id='navbar'> 
		<nav> 
			<ul>
				<li> <a href='aboutme.html'> About Me </a> </li>
				<li> <a href='resume.html'> My Resume </a> </li>
				<li> <img src='images/logo2.png' alt='flowers computer mouse and paint brush'></li>
				<li> <a href='portfolio.html'> Portfolio </a> </li>
				<li><a href='blog.html'> Blog </a> </li>
			</ul>
		</nav>
	</div>

	<h1>The Future of Artificial Intelligence</h1>

	<main>
		
		<img src='images/aipost.jpg' alt='Artificial Intelligence image' class='headerpic'>

<h2 class='headerfont'>Abstract:</h2>
<p>Artificial intelligence has been a long-time favorite topic of science fiction, making appearances in popular novels and movies dating back to 1950. Though the term “artificial intelligence” was not coined until 1956, the concept was introduced six years early by Alan Turing when he asked, “can machines think?” At this time, computers were only just being introduced to the world, so, self-admittedly, Turing did not have anything to back his curiosity (Sharkey, 2012). Now, over half a century later, the question has shifted; it is no longer “can artificial intelligence exist,” but “when will artificial intelligence become ubiquitous?”</p> 

<p>Artificial intelligence has already been integrated into our everyday lives in many aspects, but people have yet to really recognize this. In 2017, we now have voice-operated personal assistants like Siri , Cortona and Alexa. We also have behavioral algorithms that are widely used in marketing to determine how to target customers and to suggest items of interest to online shoppers. Similar algorithms are also being applied to self-driving vehicles and the technology is expected to be widely available within the next two decades (Adams, 2017). Despite its advancements, artificial intelligence is still thought to be in its infancy stage. As even further advancements are developed, there are many considerations to be made regarding societal impacts of such a huge technological leap and how to redefine the man-machine relationship.</p>

<h2 class='headerfont'>The good</h2>
<p>As with most technologies, there are several benefits to developing artificial intelligence and integrating it into our society, including: enabling the disabled, improving human capabilities, job production and improving health care, among even more applications (Reddy, n.d.). </p>

<p class='headerfont'>Enabling the Disabled </p>
<p>For many decades, individuals with physical disabilities have faced challenges when completing everyday tasks. For example, a blind person and a quadriplegic individual may both face difficulties navigating a website due shortcomings of screen readers or due to the inability to move their mouse, respectively. However, with advancements in artificial intelligence, the disabled community will be empowered with the new technology.</p>

<p>Once artificial intelligence is advanced enough to be implemented with robots, there is a potential for robotic caregivers that could provide around the clock care. Already, robots have been developed that can walk, recognize faces, and have small conversations. They have even proved to get “smarter” the more you use them. These robots, when programmed to care for disabled persons, have the potential to be the perfect caregiver. Not only do they not require breaks or pay, but they will never forget to make sure an individual takes their medicine, attends a doctors appointment, eats their meals, and so on (Irwin, 2017).</p>

<p>For blind persons, there are already options for artificial intelligence to be leveraged when using computers or commuting. The World Wide Web Consortium has guidelines that websites must meet in order to be considered “accessible,” but these guidelines are not legally enforced and most websites fail to meet even the minimum of the requirements, including the use of image descriptions. With artificial intelligence, it does not matter if an image has been labeled with a description or not because the machine will be able to accurately describe the image for the individual, whether it is an image on social media or an emoji. Artificial intelligence can also enable text-to-speech translations for the visually impaired (Irwin, 2017). Project RAY has already implemented this smart-technology into smartphones, watches, and apps to enable the visually impaired to access voice calls, messages, calendar, GPS, color identifiers, and picture transcriptions through simple gestures that are done on the screen as opposed to actually clicking on icons, to allow for eye-free access (Medcalf, 2015).  Other technologies are being created to recognize faces, read text from any surface, such as a menu, newspaper, street sign, etc., identify currency’s denomination, and distinguish between brands and products (Gutierrez, 2017).</p> 

<p>Individuals who suffer from partial paralysis and are therefore unable to control a computer mouse or interact with any other smart surface will benefit from eye tracking technology. These types of artificial intelligence devices will allow people to control their technological environment with their eyes, whether it be to zoom, scroll, or click. Everything is dictated by eye movement alone and allows the user to do anything one may do with a mouse without the use of any other muscles. This will prove to be a solution for rehabilitative and motor disabilities (Rudnicki, n.d.). </p>

<p>When commuting, artificial intelligence will allow persons with a range of disabilities to safely commute thanks to the development of self-driving cars. For the visually impaired, there is technology being developed to create a “smart cane,” which ideally will include a camera, GPS, and facial recognition software to ensure safety and accuracy when travelling on foot (Irwin, 2017). </p>

<p>Another advancement being developed for the physically disabled is a robotic exoskeleton. This skeleton, which is still in the beginning stages of development, would respond to mental commands and enable a person to walk, sit down, or control their other limbs (Irwin, 2017). </p>

<p class='headerfont'>Improving Human Capabilities</p>
<p>Technology in general is useful because it enables humans to be more efficient. For example, twenty years ago, if someone needed to research something, they had to go to the library to locate a book and find the information they are looking for.  With the widespread adoption of the Internet, this became an easier task. Today, thanks to smartphones, we are able to access nearly any information in the palm of our hands. Similarly, artificial intelligence will create a new standard of living for humans, on top of making us more efficient, this technology is predicted to actually make us smarter as well. </p>

<p>Increased human intelligence will be derived from evolving our relationship with technology from tools to partners. One example of this that has already been recorded is the use of artificially intelligent chess programs that have helped make humans better chess players. Following this logic, optimists believe that artificial intelligent programs in other disciplines may make us “’better pilots, better doctors, better judges, better teachers’” (DeAngelis, n.d.). </p>

<p>Artificial intelligence can also be applied to education to develop more intelligent students in the future. Though there are concerns with using such a technology in schools, the argument to be made is that artificial intelligence allows for a personalized learning experience, something that the classic teacher-classroom structure cannot accommodate. Intelligent Tutoring Systems are already being developed, which use artificial intelligence to teach students in a more engaging way and provide “targeted and timely feedback” (Williamson, 2016).  These “AIEd” programs are being developed using psychology and educational neuroscience to determine exactly what the best model and learning application is most effective.</p>

<p>Many companies, including IBM and Google, are leveraging neuroscience to develop cognitive learning systems, which will allow humans to naturally interact with machines and extend “human expertise and cognition” (Williamson, 2016). These cognitive learning systems will likely be implemented through neurosynaptic brain-chips, or chips that imitate the human brain, allowing them to address senses and understand language and analytical thinking. These chips, when integrated into our lives, will allow humans to extend their cognitive capabilities so that our processing is faster than ever and our ability to process information will be extremely augmented (Williamson, 2016). </p>

<p class='headerfont'>Job Production</p>
<p>There is no doubt that artificial intelligence will serve to be a disruptive technology that will eliminate many manufacturing jobs that exist today. However, it is also likely that entirely new business sectors will result from the progression of artificial intelligence (DeAngelis, n.d.). One study published by the Massachusetts Institute of Technology suggests that artificial intelligence will create three main types of jobs: trainers, explainers and sustainers (Wilson, 2017). </p>

<p>Trainers would be responsible for teaching artificial intelligence how it is supposed to perform. One example of a trainer is a person who “teaches” a natural language processor how humans speak. For chat-bots and other language-based artificial intelligence, it is important for the program to understand informal sentence structure, slang words, and other natural language patterns. At Yahoo, they have developed a natural language processor that is able to detect sarcasm 80% of the time (Wilson, 2017). This is an impressive feat considering even most humans struggle to detect sarcasm over text alone. Trainers would also be crucial in teaching algorithms to mimic humans such as exhibiting empathy (Wilson, 2017). </p>

<p>Explainers are responsible for bridging the gap between technologist and business leaders. These workers are meant to explain complex algorithms to non-technical professionals. They would also be responsible for conducting an “autopsy” on algorithms that fail to perform as expected (Wilson, 2017). </p>

<p>Sustainers will work with explainers following an autopsy to address any issues with the artificial intelligence algorithms. One example of a sustainer is an ethical compliance manager. This role would look for any ethical issues in a program’s algorithm, such as search results showing prejudice, and fix the underlying problem causing the concern (Wilson, 2017). This type of work will be crucial in reassuring business leaders that it is to their benefit to adopt artificial intelligence into their business. As of right now, many people remain skeptical of implementing such programs. Both explainers and sustainers will be a pivotal piece of easing these tensions.  </p>

<p class='headerfont'>Improving Health Care</p>

<p>As mentioned previously, artificial intelligence can be used to improve the standard of living for disabled people with the development of robot caretakers and exoskeletons that enable movement for disabled persons. However, applications of artificial intelligence in the medical field go far beyond just these two examples. Medical applications are being developed by over 800 companies, including IBM, Dell, Apple, and Highspot (Mesko, 2017).</p> 

<p>Doctors have already developed an artificial intelligent classifier that can scan human cells and diagnose the exact cells that are cancerous (Barry, 2017). In addition, artificial intelligence can be used to mine medical records. This will allow doctors to provide better and faster health services to patients. Google has developed the “Google Deepmind Health project” to do just this and is beta-testing the technology in certain hospitals. Artificial intelligence will also serve to design treatment plans that are evidence-based for patients. </p>

<p>IBM’s Watson project is currently being used with select oncologists to design treatment plans using individual medical history and common medical knowledge. IBM has also developed IBM Medical Sieve, which can analyze radiology and cardiology images. This artificial intelligence program can quickly filter through irrelevant photos and highlight any diseased regions in the images (Mesko, 2017).</p>

<p>Other companies are beginning to develop smartphone applications that use information similar to Deepmind and Watson to act as artificially intelligent health consultants. The idea is that if people are unable to schedule a doctor’s appointment, they can still receive a diagnosis and treatment plan based on personal medical history, symptoms, and common medial knowledge (Mesko, 2017).  </p>

<p>Some of the most exciting breakthroughs with artificial intelligence in the medical field are related to the human genome. Artificial intelligence programs that currently exist are able to detect patterns in genetic information and medical records that identify mutations and links to genetic diseases. This technology is the reason that classifiers are able to identify cancer cells and vascular diseases in very early stages. In addition, this information predicts what will happen to a cell if the DNA is altered, whether it be therapeutically or naturally, allowing doctors to provide premier care (Mesko, 2017). </p>

<p>Proactively understanding what changes will occur within a cell also allows drug producers to create medicines in a far shorter time span without requiring extensive testing. Atomwise has created an artificial intelligence program that is able to search through categories of existing medicines to determine translational uses for the drugs. This was very substantial when the Ebola outbreak occurred a few years ago. Atomwise was able to identify two medicines in just two days that dramatically lessen the symptoms of Ebola. If this same task was performed by humans, it would take months or even years complete (Mesko, 2017).</p>

<h2>The Bad</h2>

Despite the numerous benefits that artificial intelligence can create, it would be irresponsible to ignore potential downfalls of widespread adoption of advanced artificial technology, including dehumanization, increased warfare, and mass idleness due to job loss (Kile, 2012).

<p class='headerfont'>Dehumanization</p>
<p>Dehumanization will become apparent as artificial intelligence become ubiquitous due to the unclear definition of what it really means to be a human. With improved artificial intelligence, many of our everyday tasks and jobs will be replaced. So, this makes us ask: what does it mean to be a human? There are certain traits that as of right now are embodied strictly by humans, including the ability to feel emotions, the need to feel part of an organization, and the search for a meaning of life (Kile, 2012). However, it is unclear whether or not advanced artificial intelligence will being mimicking these traits, blurring the lines of humanity. </p>

<p>Thanks to natural language processing, we are able to talk to computers and feel like we are talking to another human being (Kile, 2012).  One example of this was recently introduced by Group Me, a popular messaging app. The app introduced a Group Me chat bot that they encourage users to add into their group messages as an added “friend.” The chat bot reacts to the conversation you and your friends are having with funny comments, jokes, and sarcasm. This makes some people nervous that this type of technology combined with an increasing ease of use of artificial intelligence will begin to replace human relationships and redefine what a human really is.</p>

<p class='headerfont'>Increased Warfare</p>
<p>Throughout history, warfare has become less and less personal. Centuries ago, soldiers were required to be face to face with their enemies, but thanks to the invention of long-range rifles, people became detached from the people they were killing. Now, with the press of a button, we are able to shoot missiles and accurately hit targets hundreds of miles away. With advanced artificial intelligence, not only will warfare become even more depersonalized, but there is a potential for attacks to be automated (Kile, 2012).  The worry is that if we do automate defense systems, we are giving artificially intelligent programs the ability to potentially launch very serious attacks without human intervention. <p>

<p class='headerfont'>Job Loss & Mass Idleness</p>
<p>This report previously listed the jobs that will be produced thanks to the artificial intelligence, but there is no denying that an unprecedented amount of jobs will be eliminated with the advancement of this disruptive technology. Some projections say that upwards of 50% of the workforce will be displaced by artificial intelligence by the year 2030 (Weller, 2017). Jobs from almost any industry can easily be replaced by automated processes, whether it be cashiers in a grocery store, manufacturing jobs, or customer services representatives. </p>

<p>One profession that seemed safe from the artificial intelligence takeover was journalism. However, many news sources already use artificial intelligence to write articles, most of which are data-heavy stock and sports articles. In November of 2016, The Post used artificial intelligence robots to write an article about a congressional race in Iowa that was both insightful and exploratory (Keohane, 2017). This made people fear that even creative jobs will eventually be replaced by artificial intelligence.</p>

<p>The major problem with mass unemployment is mass idleness, which often leads to riots and rebellions among unemployed masses (Kile, 2012). In order to address this issue, many artificial intelligence researchers, including Elon Musk, are pushing for basic minimum income to be implemented. This would mean that individuals and families would be granted a certain income regardless of whether not they work in order to afford a home, clothing and food (Weller, 2017).  Although this system is not perfect, there will need to be some form of social welfare in place assuming that half the population will be unemployed within the next few decades.</p>

<h2>Conclusion</h2>
<p>With the age of ubiquitous artificial intelligence on the horizon, it is important that as a society, we begin to understand the impact that this new technology will have on our world.  It is undeniable that such a revolutionary technological advancement will make humans more efficient and capable. However, it is crucial that policy makers and world leaders are proactive about creating guidelines to regulate artificial intelligence before it is too out of control to reel back in. Whether it is in hospitals, schools, or homes, artificial intelligence is guaranteed to change the way we go about our days. Understanding the power of artificial intelligence will be vital to remaining responsible as the technology continues to be developed. </p>


<h2>Works Cited</h2>

<p>Adams, R. (2017). 10 Powerful Examples of Artificial Intelligence in use Today. [online] Forbes. Available at: https://www.forbes.com/sites/robertadams/2017/01/10/10-powerful-examples-of-artificial-intelligence-in-use-today/ [Accessed 1 Sep. 2017].</p>

<p>Barry, C. (2017). Humanistic AI- Making Humans Smarter Using AI?. [online] Forecast. Available at: https://www.forcecast.com/blog/humanistic-ai-what-is-does-it-mean/ [Accessed 1 Sep. 2017]. </p>

<p>DeAngelis, S. (n.d.). The Upside of Artificial Intelligence Development. [online] WIRED. Available at: https://www.wired.com/insights/2015/02/the-upside-of-artificial-intelligence-development/ [Accessed 31 Aug. 2017]. </p>

<p>Gutierrez, C. (2017). Artificial Intelligence is Helping the Visually Impaired. [online] HuffPost. Available at: http://www.huffingtonpost.com/entry/how-artificial-intelligence-is-helping-the-visually_us_58ed5c09e4b0145a227cb963 [Accessed 31 Aug. 2017].</p>

<p>Hudson, A. (2017). '40% of Jobs' Taken by Robots by 2030, but AI Companies Say They're Here to Help. [online] Metro. Available at: http://metro.co.uk/2017/05/10/40-of-jobs-taken-by-robots-by-2030-but-ai-companies-say-theyre-here-to-help-6628469/ [Accessed 1 Sep. 2017].</p>

<p>Irwin, P. (2017). How Artificial Intelligence Can Help with Disabilities. [online] Knowmail. Available at: https://www.knowmail.me/blog/artificial-intelligence-can-help-disabilities/ [Accessed 1 Sep. 2017].</p>

<p>Keohane, J. (2017). What News-Writing Bots Mean for the Future of Journalism. [online] WIRED. Available at: https://www.wired.com/2017/02/robots-wrote-this-story/ [Accessed 2 Sep. 2017].</p>

<p>Kile, F. “Artificial Intelligence and Society: A Furtive Transformation,” Springer, vol. 28, pp. 107–115, Feb. 2012.</p>

<p>Medcalf, L. (2015). Project RAY: Devices for the Blind and Visually Impaired. [online] Easterseals Crossroads. Available at: http://www.eastersealstech.com/2015/04/15/project-ray-devices-for-the-blind-and-visually-impaired/ [Accessed 29 Aug. 2017].</p>

<p>Mesko, B. (2017). Artificial Intelligence Will Redesign Healthcare. [online] Medical Futurist. Available at: http://medicalfuturist.com/artificial-intelligence-will-redesign-healthcare/ [Accessed 1 Sep. 2017].</p>


<p>Reddy, K. (n.d.). Advantages and Disadvantages of Artificial Intelligence. [online] Wisestep. Available at: https://content.wisestep.com/advantages-disadvantages-artificial-intelligence/ [Accessed 1 Sep. 2017].</p>

<p>Rudnicki, T. (n.d.). Eye-Control Empowers People with Disabilities. [online] Abilities. Available at: http://www.abilities.com/community/assistive_eye-control.html [Accessed 1 Sep. 2017].</p>

<p>Sharkey, N. (2012). Alan Turing: The Experiment that Shaped Artificial Intelligence. [online] BBC News. Available at: http://www.bbc.com/news/technology-18475646/ [Accessed 31 Aug. 2017]. </p> 

<p>Weller, C. (2017). Elon Musk Doubles Down on Universal Income: "It's Going to be Necessary". [online] Business Insider. Available at: http://www.businessinsider.com/elon-musk-universal-basic-income-2017-2 [Accessed 1 Sep. 2017].</p>

<p>Williamson, B. (2016). Aritificial Intelligence, Cognitive Systems and the Learning Brain. [online] DML Central. Available at: https://dmlcentral.net/artificial-intelligence-cognitive-systems-learning-brain/ [Accessed 31 Aug 2017]. </p>

<p>Wilson, J. Daugherty, P., and Morini-Bianzino, N., “The Jobs that Artificial Intelligence Will Create,” MIT Sloan, 23-Mar-2017. [Online]. Available: http://sloanreview.mit.edu/article/will-ai-create-as-many-jobs-as-it-eliminates/. [Accessed: 31 Aug 2017].</p>

<div class='button'>
	<a href='blog.html' class='goback'> Go Back </a>
</div>

</main>



</html>
